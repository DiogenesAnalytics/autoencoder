{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e1218c-0556-4cbc-b6a2-16793e855d3c",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "The following `Jupyter Notebook` has been *adapted* from the [Keras blog article](https://blog.keras.io/building-autoencoders-in-keras.html) written by *F. Chollet* on [autoencoders](https://en.wikipedia.org/wiki/Autoencoder), and will focus on training the `MinimalAutoencoder` (aka *vanilla autoencoder*) on the `MNIST` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081d420-b402-4e20-835a-c5c002c6d326",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Need to get the necessary packages ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4308136-9bea-4e1a-aa6d-9031c7f374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for colab\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "  # install colab dependencies\n",
    "  !pip install git+https://github.com/DiogenesAnalytics/autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194012cf-2b20-4261-9579-38cd2fd4fd1d",
   "metadata": {},
   "source": [
    "## Get MNIST Data\n",
    "Wille use `keras.datasets` to get the `MNIST` dataset, and then do some *normalizing* and *reshaping* to prepare it for the *autoencoder*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db702b19-0dc6-482e-8315-01643d23e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get necessary libs for data/preprocessing\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load the data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# preprocess the data (normalize)\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_test = x_test.astype(\"float32\") / 255.\n",
    "\n",
    "# convert to tf datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, x_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, x_test))\n",
    "\n",
    "# set a few params\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "# update with batch/buffer size\n",
    "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208d9d4-5350-4815-88f5-0233d0c53bd6",
   "metadata": {},
   "source": [
    "## Autoencoder Training\n",
    "Finally the *autoencoder* can be trained ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d440a72-b357-4794-a5b9-f4b4ee790524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get libs for training ae\n",
    "from autoencoder.model.minimal import Min2DAE, Min2DParams\n",
    "\n",
    "# seupt config\n",
    "config = Min2DParams(\n",
    "    l0={\"input_shape\": (28, 28)},\n",
    "    l2={\"units\": 32 * 1},\n",
    "    l3={\"units\": 28 * 28 * 1},\n",
    "    l4={\"target_shape\": (28, 28)},\n",
    ")\n",
    "\n",
    "# get ae instance\n",
    "autoencoder = Min2DAE(config)\n",
    "\n",
    "# check network topology\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da883534-e913-494b-bafe-564d8b25f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get early stopping class\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# create callback\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "\n",
    "# compile ae\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# begin model fit\n",
    "autoencoder.fit(\n",
    "    x=train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[early_stop_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece10e9-bcd3-44f9-a15d-bf2ed9b06e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view training loss\n",
    "autoencoder.training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c110a-0a08-4015-b3d1-eb17e991833e",
   "metadata": {},
   "source": [
    "## Visualizing Predictions\n",
    "Now it is possible, using the trained autoencoder, to encode/decode an image and see how it compares to the original ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a4180-ca54-437d-abc4-21427f45eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get viz func\n",
    "from autoencoder.data import compare_image_predictions\n",
    "\n",
    "# get samples from validation dataset\n",
    "val_samples = test_ds.take(1)\n",
    "\n",
    "# get raw numpy arrays\n",
    "val_input = [item for pair in val_samples.as_numpy_iterator() for item in pair[0]]\n",
    "\n",
    "# and decoded\n",
    "decoded_imgs = autoencoder.predict(x=val_samples)\n",
    "\n",
    "# display\n",
    "compare_image_predictions(val_input, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299de94-d802-4d3d-82c5-875ddde80232",
   "metadata": {},
   "source": [
    "## Reconstruction Error Distribution\n",
    "Now let us take peak into this dataset and see how well the *autoencoder* is capturing the image features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9bac7-2902-4ea7-9c06-216584369c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get custom class\n",
    "from autoencoder.data.evaluate import AutoencoderEvaluator\n",
    "\n",
    "# get instance\n",
    "ae_eval = AutoencoderEvaluator(autoencoder, test_ds, axis=(1, 2))\n",
    "\n",
    "# view distribution\n",
    "ae_eval.view_error_distribution(\"MNIST Autoencoder: Reconstruction Error Distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
